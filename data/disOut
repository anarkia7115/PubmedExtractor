26390422|t|-No title-
26390422|a|<AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">An altered anatomy such as after pancreatoduodenectomy is currently seen as relative contraindication for bedside electromagnetic (EM)-guided nasojejunal feeding tube placement. The aim of this study was to determine the feasibility and safety of bedside EM-guided placement of nasojejunal feeding tubes as compared with endoscopy in patients after pancreatoduodenectomy. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">We performed a prospective monocenter pilot study in patients requiring enteral feeding after pancreatoduodenectomy (July 2012-March 2014). Primary end point was the success rate of primary tube placement confirmed on plain abdominal x-ray followed by successful enteral feeding. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">Overall, 53 (42%) of 126 patients who underwent pancreatoduodenectomy required a nasojejunal feeding tube, of which 36 were placed under EM guidance and, in 17, it was placed by endoscopy. Initial tube placement was successful in 21 (58%) of 36 patients with EM guidance and 9 (53%) of 17 patients with endoscopy (P = 0.71). No complications occurred during the placement procedures. Dislodgement and/or blockage of the tube occurred in 14 (39%) of 36 patients in the EM-guided group and 8 (47%) of 17 patients in the endoscopic group (P = 0.57). </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">Bedside EM-guided placement of nasojejunal feeding tubes by nurses was equally successful as endoscopic placement in patients after pancreatoduodenectomy. </AbstractText>

26390423|t|-No title-
26390423|a|<AbstractText Label="OBJECTIVES" NlmCategory="OBJECTIVE">There is limited knowledge of the prognostic indicators after hospital discharge after acute pancreatitis (AP). The aim was to determine risk factors for mortality after discharge in patients admitted with AP. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">A retrospective cohort study was conducted, including consecutive patients with AP admitted to the Cleveland Clinic between 2007 and 2011. Clinical data, mortality status, and the date of death were collected. Univariable and multivariable Cox regression was performed to determine variables significantly associated with mortality within a year of discharge. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">Three hundred thirty-one patients were included in the study, current to July 2012. After a mean follow-up of 20 months, 41 subjects (12.4%) died after discharge from the hospital. Thirty-three (10.0%) died within a year after discharge. In univariable analyses, higher Charlson Comorbidity Index, blood urea nitrogen > 20 on admission, higher Bedside Index of Severity in Acute Pancreatitis scores, longer length of stay, and readmission within 30 days were associated with a higher hazard of mortality. In the multivariable analysis, subjects who were readmitted within 30 days had a 4.5 times higher hazard of dying within a year than those who were not readmitted (hazard ratio, 4.5; 95% confidence interval, 2.2-9.1). </AbstractText><AbstractText Label="CONCLUSION" NlmCategory="CONCLUSIONS">A higher Charlson Comorbidity Index, early readmission, and longer hospitalization predict a higher 1-year mortality after AP. </AbstractText>
26390423	155	173	acute pancreatitis	Disease	MESH:D019283
26390423	175	177	AP	Disease	MESH:D019283
26390423	274	276	AP	Disease	MESH:D019283
26390423	425	427	AP	Disease	MESH:D019283
26390423	1145	1163	Acute Pancreatitis	Disease	MESH:D019283
26390423	1692	1694	AP	Disease	MESH:D019283

26390424|t|-No title-
26390424|a|<AbstractText Label="OBJECTIVES" NlmCategory="OBJECTIVE">We sought to determine whether hypotension and the amount of intravenous (IV) fluids administered during endoscopic retrograde cholangiopancreatography (ERCP) were associated with post-ERCP pancreatitis. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">We identified patients who developed post-ERCP pancreatitis between 2009 and 2013. Using a case-control design, we extracted baseline and intra-ERCP vital signs and the amount of IV fluids given. We used regression to analyze the association between these factors and the risk of post-ERCP pancreatitis. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">We found no association between intraprocedure hypotension (P = 0.17), bradycardia (P = 0.20), hypoxemia (P = 1.0), dehydration (P = 0.80), and post-ERCP pancreatitis. An increase in mean arterial pressure (MAP) more than 20 units from baseline (odds ratio [OR], 1.8; P = 0.03), increasing amount of IV fluids administered during ERCP (OR, 1.5; P = 0.03), female sex (OR, 2.6; P = 0.001), and younger age (OR, 1.02; P = 0.01) were associated with post-ERCP pancreatitis. In multivariate regression, female sex maintained statistical significance (P = 0.01); MAP more than 20 units from baseline (P = 0.1) and increased IV fluids (P = 0.09) showed an insignificant trend. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">Hypotension during ERCP was not associated with post-ERCP pancreatitis. An increase in MAP more than 20 units from baseline and an increase in the amount of IV fluids administered during ERCP may increase the risk of post-ERCP pancreatitis. </AbstractText>
26390424	184	219	retrograde cholangiopancreatography	Disease	MESH:D012183
26390424	781	792	bradycardia	Disease	MESH:D001919
26390424	805	814	hypoxemia	Disease	MESH:D000860
26390424	893	915	mean arterial pressure	Disease	MESH:D003668
26390424	917	920	MAP	Disease	MESH:D003668
26390424	1268	1271	MAP	Disease	MESH:D003668
26390424	1543	1546	MAP	Disease	MESH:D003668

26390425|t|-No title-
26390425|a|<AbstractText Label="OBJECTIVES" NlmCategory="OBJECTIVE">Tumor necrosis factor (TNF)-related apoptosis-inducing ligand (TRAIL) is currently being evaluated as a possible biological agent for cancer treatment. However, many tumor cells are resistant to TRAIL-induced apoptosis. In these cases, TRAIL may activate different pathways promoting tumor growth as well as showing different interactions with the immunological tumor microenvironment. In this study, the impact of TRAIL on tumor growth and survival in a syngeneic model of TRAIL-resistant pancreatic cancer cells was investigated. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">Murine 6606PDA pancreatic cancer cells were injected into the pancreatic heads of TRAIL mice and their littermates. To examine a direct effect of TRAIL on tumor cells, cultures of 6606PDA were TRAIL stimulated. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">The TRAIL mice displayed significantly decreased tumor volumes and an enhanced overall survival in pancreatic cancer. The decreased tumor growth in TRAIL mice was accompanied by a decrease of regulatory CD4 cells within tumors. Concordantly, TRAIL treatment of wild-type mice enhanced tumor growth and increased the fraction of regulatory CD4 cells. Yet, a direct effect of TRAIL on 6606PDA cells was not detected. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">Thus, TRAIL can promote tumor growth in TRAIL-resistant tumor cells. This may restrict possible future clinical applications of TRAIL in pancreatic cancer. </AbstractText>
26390425	68	82	Tumor necrosis	Disease	MESH:D009336
26390425	202	208	cancer	Disease	MESH:D009369
26390425	234	239	tumor	Disease	MESH:D009369
26390425	352	357	tumor	Disease	MESH:D009369
26390425	430	435	tumor	Disease	MESH:D009369
26390425	492	497	tumor	Disease	MESH:D009369
26390425	558	575	pancreatic cancer	Disease	MESH:D010190
26390425	682	699	pancreatic cancer	Disease	MESH:D010190
26390425	822	827	tumor	Disease	MESH:D009369
26390425	984	1007	decreased tumor volumes	Disease	MESH:D012021
26390425	1044	1061	pancreatic cancer	Disease	MESH:D010190
26390425	1077	1082	tumor	Disease	MESH:D009369
26390425	1165	1171	tumors	Disease	MESH:D009369
26390425	1230	1235	tumor	Disease	MESH:D009369
26390425	1459	1464	tumor	Disease	MESH:D009369
26390425	1491	1496	tumor	Disease	MESH:D009369
26390425	1572	1589	pancreatic cancer	Disease	MESH:D010190

26390426|t|-No title-
26390426|a|<AbstractText Label="OBJECTIVES" NlmCategory="OBJECTIVE">There are plausible biological mechanisms for how increased physical activity (PA) may prevent pancreatic cancer, although findings from epidemiological studies are inconsistent. We investigated whether the risk is dependent on the age at which PA is measured and if independent of body mass index (BMI). </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">A total of 23,639 participants, aged 40 to 74 years, were recruited into the EPIC-Norfolk (European Prospective Investigation of Cancer) cohort study between 1993 and 1997 and completed validated questionnaires on PA. The cohort was monitored for pancreatic cancer development, and hazard ratios (HRs) were estimated and adjusted for covariates. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">Within 17 years, 88 participants developed pancreatic cancer (55% female). There was no association between PA and risk in the cohort (HR trend, 1.06; 95% confidence interval [CI], 0.86-1.29). However, in participants younger than 60 years, higher PA was associated with decreased risk (highest vs lowest category HR, 0.27; 95% CI, 0.07-0.99). Higher PA was not inversely associated when older than 60 years (HR trend, 1.23; 95% CI, 0.96-1.57). Including BMI in all models produced similar estimates. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">The reasons why PA in younger, but not older, people may prevent pancreatic cancer need to be investigated. Physical activity may operate through mechanisms independent of BMI. If this association is causal, 1 in 6 cases might be prevented by encouraging more PA. </AbstractText>
26390426	163	180	pancreatic cancer	Disease	MESH:D010190
26390426	687	704	pancreatic cancer	Disease	MESH:D010190
26390426	896	913	pancreatic cancer	Disease	MESH:D010190
26390426	1494	1511	pancreatic cancer	Disease	MESH:D010190

26390427|t|-No title-
26390427|a|<AbstractText Label="OBJECTIVES" NlmCategory="OBJECTIVE">The prognosis of pancreatic cancer (PC) is poor and the pathogenesis of PC-associated diabetes is unknown. We investigated the possible expression of immunoglobulin G (IgG) in human pancreatic carcinomas and adjacent pancreatic islets to gain a better understanding of these diseases. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">We employed immunohistochemistry, Western Blot, real-time polymerase chain reaction, and in situ hybridization to examine IgG expression in PC tissues and adjacent islets with and without cancer-associated diabetes. The IgG mRNA and IgG synthesizing-related enzymes were examined in PC cell lines. The IgG expression and secretion were downregulated with specific small interfering RNA and antibody to IgG followed by flow cytometry to assess its effect on apoptosis of cultured PC cells. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">The expression of IgG was detected in pancreatic carcinoma and adjacent islets. Small interfering RNA and antibody treatments induced apoptosis in PC cell lines. In the carcinoma tissue, the levels of IgG expression varied depending on the stages of the cancers with more malignant cancers expressing more IgG (P < 0.05). The IgG levels in cancer cells were also increased when the patients had diabetes or hyperglycemia (P < 0.05). In addition, the extent of IgG expression in the seemingly normal islet cells adjacent to the tumor varied in relation to the grade of cancer differentiation and distance to the cancer nests. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">(1) Immunoglobulin G was locally produced by PC cells and adjacent islet cells. (2) Immunoglobulin G may promote tumor growth by inhibiting cancer cell apoptosis. (3) Locally produced IgG might play a role in PC-associated diabetes. </AbstractText>
26390427	85	102	pancreatic cancer	Disease	MESH:D010190
26390427	104	106	PC	Disease	MESH:D010190
26390427	140	142	PC	Disease	MESH:D010190
26390427	154	162	diabetes	Disease	MESH:D003929
26390427	250	271	pancreatic carcinomas	Disease	MESH:D010190
26390427	560	562	PC	Disease	MESH:D010190
26390427	608	614	cancer	Disease	MESH:D009369
26390427	626	634	diabetes	Disease	MESH:D003929
26390427	703	705	PC	Disease	MESH:D010190
26390427	899	901	PC	Disease	MESH:D010190
26390427	1014	1034	pancreatic carcinoma	Disease	MESH:D010190
26390427	1123	1125	PC	Disease	MESH:D010190
26390427	1145	1154	carcinoma	Disease	MESH:D002277
26390427	1230	1237	cancers	Disease	MESH:D009369
26390427	1258	1265	cancers	Disease	MESH:D009369
26390427	1316	1322	cancer	Disease	MESH:D009369
26390427	1371	1379	diabetes	Disease	MESH:D003929
26390427	1383	1396	hyperglycemia	Disease	MESH:D006943
26390427	1503	1508	tumor	Disease	MESH:D009369
26390427	1544	1550	cancer	Disease	MESH:D009369
26390427	1587	1593	cancer	Disease	MESH:D009369
26390427	1721	1723	PC	Disease	MESH:D010190
26390427	1789	1794	tumor	Disease	MESH:D009369
26390427	1816	1822	cancer	Disease	MESH:D009369
26390427	1885	1887	PC	Disease	MESH:D010190
26390427	1899	1907	diabetes	Disease	MESH:D003929

26390428|t|-No title-
26390428|a|<AbstractText Label="OBJECTIVES" NlmCategory="OBJECTIVE">In mouse models of pancreatic cancer, IPI-926, an oral Hedgehog inhibitor, increases chemotherapy delivery by depleting tumor-associated stroma. This multicenter phase Ib study evaluated IPI-926 in combination with FOLFIRINOX (5-fluorouracil, leucovorin, irinotecan, oxaliplatin) in patients with advanced pancreatic cancer. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">Patients were treated with once-daily IPI-926 plus FOLFIRINOX. A 3 + 3 dose escalation design was used, with cohort expansion at the maximum tolerated dose. A subset of patients underwent perfusion computed tomography to assess changes in tumor perfusion. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">The maximum tolerated dose was identified 1 dose level below standard FOLFIRINOX. Common treatment-related adverse events included liver function test abnormalities, neuropathy, nausea/vomiting, and diarrhea. Objective response rate was high (67%), and patients receiving IPI-926 maintenance showed further declines in CA19-9 levels even after FOLFIRINOX discontinuation. Treatment did not result in consistent increases in tumor perfusion. The study closed early when a separate phase II trial of IPI-926 plus gemcitabine indicated detrimental effects of this combination. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">This is the first study to demonstrate the feasibility of using FOLFIRINOX as the chemotherapeutic backbone in a clinical trial design. Although robust antitumor activity and acceptable safety were observed with the addition of IPI-926 to this regimen, future development of Hedgehog inhibitors in pancreatic cancer seems unlikely. </AbstractText>
26390428	87	104	pancreatic cancer	Disease	MESH:D010190
26390428	188	193	tumor	Disease	MESH:D009369
26390428	374	391	pancreatic cancer	Disease	MESH:D010190
26390428	699	704	tumor	Disease	MESH:D009369
26390428	949	959	neuropathy	Disease	MESH:D003929
26390428	1207	1212	tumor	Disease	MESH:D009369
26390428	1730	1747	pancreatic cancer	Disease	MESH:D010190

26390429|t|-No title-
26390429|a|<AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">The objective of this study was to investigate the relationship between asymmetric dimethylarginine (ADMA), an endogenous nitric oxide synthase inhibitor, oxidative-nitrosative damage, and glucoregulation in acute pancreatitis (AP). </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">The study evaluated serum levels of ADMA, nitrotyrosine, and urinary 8-hydroxydeoxyguanosine in 40 male patients hospitalized for AP at baseline and at 2 and 10 days of treatment, respectively. The patients were classified into a mild and a moderately severe AP group (MAP and MSAP, respectively) according to Atlanta classification criteria. Glycemic status was evaluated by a 75-g oral glucose tolerance test 1 month after AP onset. Forty age-matched healthy subjects served as control subjects. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">Significant decrease of ADMA and increased levels of nitrotyrosine and urinary 8-hydroxydeoxyguanosine were found in MSAP, but not in MAP at baseline, with ADMA correction toward control levels at the 10th day of treatment. Fructosamine was found to significantly influence ADMA levels (r = -0.362, P = 0.002). After AP recovery, either impaired glucose tolerance or diabetes was identified with the oral glucose tolerance test in 10.5% and 92.8% of patients with MAP and MSAP, respectively. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">Insufficient inhibition of nitric oxide synthesis, through reduced bioavailability of ADMA, might be a novel significant contributory factor to the severity of AP and subsequent development of hyperglycemia. </AbstractText>
26390429	275	293	acute pancreatitis	Disease	MESH:D019283
26390429	295	297	AP	Disease	MESH:D019283
26390429	497	499	AP	Disease	MESH:D019283
26390429	626	628	AP	Disease	MESH:D019283
26390429	636	639	MAP	Disease	MESH:C535477
26390429	792	794	AP	Disease	MESH:D019283
26390429	1066	1069	MAP	Disease	MESH:C535477
26390429	1249	1251	AP	Disease	MESH:D019283
26390429	1269	1307	impaired glucose tolerance or diabetes	Disease	MESH:D044882
26390429	1396	1399	MAP	Disease	MESH:C535477
26390429	1659	1661	AP	Disease	MESH:D019283
26390429	1692	1705	hyperglycemia	Disease	MESH:D006943

26390430|t|-No title-
26390430|a|<AbstractText Label="BACKGROUND" NlmCategory="BACKGROUND">Incidence and prevalence studies of neurological disorders play an extremely important role in hypothesis-generation, assessing the burden of disease and planning of health services. However, the assessment of disease estimates is hindered by the poor quality of reporting for such studies. We developed the Standards of Reporting of Neurological Disorders (STROND) guideline in order to improve the quality of reporting of neurological disorders from which prevalence, incidence, and outcomes can be extracted for greater generalisability. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">The guideline was developed using a 3-round Delphi technique in order to identify the 'basic minimum items' important for reporting, as well as some additional 'ideal reporting items.' An e-consultation process was then used in order to gauge opinion by external neuroepidemiological experts on the appropriateness of the items included in the checklist. </AbstractText><AbstractText Label="FINDINGS" NlmCategory="RESULTS">The resultant 15 items checklist and accompanying recommendations were developed using a similar process and structured in a similar manner to the Strengthening of the Reporting of Observational Studies in Epidemiology checklist for ease of use. This paper presents the STROND checklist with an explanation and elaboration for each item, as well as examples of good reporting from the neuroepidemiological literature. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">The introduction and use of the STROND checklist should lead to more consistent, transparent and contextualised reporting of descriptive neuroepidemiological studies that should facilitate international comparisons, and lead to more accessible information for multiple stakeholders, ultimately supporting better healthcare decisions for neurological disorders. </AbstractText>
26390430	105	127	neurological disorders	Disease	MESH:D009422
26390430	403	425	Neurological Disorders	Disease	MESH:D009422
26390430	493	515	neurological disorders	Disease	MESH:D009422
26390430	1930	1952	neurological disorders	Disease	MESH:D009422

26390431|t|-No title-
26390431|a|<AbstractText Label="null" NlmCategory="UNLABELLED">The N-isopropylammelide isopropylaminohydrolase from Pseudomonas sp. strain ADP, AtzC, provides the third hydrolytic step in the mineralization of s-triazine herbicides, such as atrazine. We obtained the X-ray crystal structure of AtzC at 1.84 Å with a weak inhibitor bound in the active site and then used a combination of in silico docking and site-directed mutagenesis to understand the interactions between AtzC and its substrate, isopropylammelide. The substitution of an active site histidine residue (His249) for an alanine abolished the enzyme's catalytic activity. We propose a plausible catalytic mechanism, consistent with the biochemical and crystallographic data obtained that is similar to that found in carbonic anhydrase and other members of subtype III of the amidohydrolase family. </AbstractText>
26390431	821	854	subtype III of the amidohydrolase	Disease	MESH:C535673

26390432|t|-No title-
26390432|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Nontypeable Haemophilus influenzae (NTHi) cause significant disease, including otitis media in children, exacerbations of chronic obstructive pulmonary disease, and invasive disease in susceptible populations. No vaccine is currently available to prevent NTHi disease. The interactions of NTHi and the human host are primarily mediated by lipooligosaccharide and a complex array of surface-exposed proteins (SEPs) that act as receptors, sensors and secretion systems. We hypothesized that certain SEPs are present in all NTHi strains and that a subset of these may be antibody accessible and represent protective epitopes. Initially we used 15 genomic sequences available in the GenBank database along with an additional 11 genomic sequences generated by ourselves to identify the core set of putative SEPs present in all strains. Using bioinformatics, 56 core SEPs were identified. Molecular modeling generated putative structures of the SEPs from which potential surface exposed regions were defined. Synthetic peptides corresponding to ten of these highly conserved surface-exposed regions were used to raise antisera in rats. These antisera were used to assess passive protection in the infant rat model of invasive NTHi infection. Five of the antisera were protective, thus demonstrating their in vivo antibody accessibility. These five peptide regions represent potential targets for peptide vaccine candidates to protect against NTHi infection. </AbstractText>
26390432	75	97	Haemophilus influenzae	Disease	MESH:D008583
26390432	142	154	otitis media	Disease	MESH:D010033
26390432	185	222	chronic obstructive pulmonary disease	Disease	MESH:D029424
26390432	318	330	NTHi disease	Disease	MESH:D008583

26390433|t|-No title-
26390433|a|<AbstractText Label="null" NlmCategory="UNLABELLED">B-type natriuretic peptide (BNP) is often used as a complementary finding in the diagnostic work-up of patients with aortic stenosis (AS). Whether soluble ST2, a new biomarker of cardiac stretch, is associated with symptomatic status and outcome in asymptomatic AS is unknown. sST2 and BNP levels were measured in 86 patients (74±13 years; 59 asymptomatic, 69%) with AS (<1.5 cm2) and preserved left ventricular ejection fraction who were followed-up for 26±16 months. Both BNP and sST2 were associated with NYHA class but sST2 (>23 ng/mL, AUC = 0.68, p<0.01) was more accurate to identify asymptomatic patients or those who developed symptoms during follow-up. sST2 was independently related to left atrial index (p<0.0001) and aortic valve area (p = 0.004; model R2 = 0.32). A modest correlation was found with BNP (r = 0.4, p<0.01). During follow-up, 29 asymptomatic patients (34%) developed heart failure symptoms. With multivariable analysis, peak aortic jet velocity (HR = 2.7, p = 0.007) and sST2 level (HR = 1.04, p = 0.03) were independent predictors of cardiovascular events. In AS, sST2 levels could provide complementary information regarding symptomatic status, new onset heart failure symptoms and outcome. It might become a promising biomarker in these patients. </AbstractText>
26390433	180	195	aortic stenosis	Disease	MESH:D001024
26390433	197	199	AS	Disease	MESH:D001024
26390433	325	327	AS	Disease	MESH:D001024
26390433	430	432	AS	Disease	MESH:D001024
26390433	958	980	heart failure symptoms	Disease	MESH:D006333
26390433	1152	1154	AS	Disease	MESH:D001024
26390433	1248	1270	heart failure symptoms	Disease	MESH:D006333

26390434|t|-No title-
26390434|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Social media are increasingly reflecting and influencing behavior of other complex systems. In this paper we investigate the relations between a well-known micro-blogging platform Twitter and financial markets. In particular, we consider, in a period of 15 months, the Twitter volume and sentiment about the 30 stock companies that form the Dow Jones Industrial Average (DJIA) index. We find a relatively low Pearson correlation and Granger causality between the corresponding time series over the entire time period. However, we find a significant dependence between the Twitter sentiment and abnormal returns during the peaks of Twitter volume. This is valid not only for the expected Twitter volume peaks (e.g., quarterly announcements), but also for peaks corresponding to less obvious events. We formalize the procedure by adapting the well-known "event study" from economics and finance to the analysis of Twitter data. The procedure allows to automatically identify events as Twitter volume peaks, to compute the prevailing sentiment (positive or negative) expressed in tweets at these peaks, and finally to apply the "event study" methodology to relate them to stock returns. We show that sentiment polarity of Twitter peaks implies the direction of cumulative abnormal returns. The amount of cumulative abnormal returns is relatively low (about 1-2%), but the dependence is statistically significant for several days after the events. </AbstractText>

26390435|t|-No title-
26390435|a|<AbstractText Label="null" NlmCategory="UNLABELLED">The main objectives of this work were to investigate the effect of atmospheric cold plasma (ACP) against a range of microbial biofilms commonly implicated in foodborne and healthcare associated human infections and against P. aeruginosa quorum sensing (QS)-regulated virulence factors, such as pyocyanin, elastase (Las B) and biofilm formation capacity post-ACP treatment. The effect of processing factors, namely treatment time and mode of plasma exposure on antimicrobial activity of ACP were also examined. Antibiofilm activity was assessed for E. coli, L. monocytogenes and S. aureus in terms of reduction of culturability and retention of metabolic activity using colony count and XTT assays, respectively. All samples were treated 'inpack' using sealed polypropylene containers with a high voltage dielectric barrier discharge ACP generated at 80 kV for 0, 60, 120 and 300 s and a post treatment storage time of 24 h. According to colony counts, ACP treatment for 60 s reduced populations of E. coli to undetectable levels, whereas 300 s was necessary to significantly reduce populations of L. monocytogenes and S. aureus biofilms. The results obtained from XTT assay indicated possible induction of viable but non culturable state of bacteria. With respect to P. aeruginosa QS-related virulence factors, the production of pyocyanin was significantly inhibited after short treatment times, but reduction of elastase was notable only after 300 s and no reduction in actual biofilm formation was achieved post-ACP treatment. Importantly, reduction of virulence factors was associated with reduction of the cytotoxic effects of the bacterial supernatant on CHO-K1 cells, regardless of mode and duration of treatment. The results of this study point to ACP technology as an effective strategy for inactivation of established biofilms and may play an important role in attenuation of virulence of pathogenic bacteria. Further investigation is warranted to propose direct evidence for the inhibition of QS and mechanisms by which this may occur. </AbstractText>
26390435	130	153	atmospheric cold plasma	Disease	MESH:D003139
26390435	155	158	ACP	Disease	MESH:D003139
26390435	421	424	ACP	Disease	MESH:D003139
26390435	549	552	ACP	Disease	MESH:D003139
26390435	896	899	ACP	Disease	MESH:D003139
26390435	1015	1018	ACP	Disease	MESH:D003139
26390435	1577	1580	ACP	Disease	MESH:D003139
26390435	1818	1821	ACP	Disease	MESH:D003139

26390436|t|-No title-
26390436|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Integration of multiple profiling data and construction of functional gene networks may provide additional insights into the molecular mechanisms of complex diseases. Osteoporosis is a worldwide public health problem, but the complex gene-gene interactions, post-transcriptional modifications and regulation of functional networks are still unclear. To gain a comprehensive understanding of osteoporosis etiology, transcriptome gene expression microarray, epigenomic miRNA microarray and methylome sequencing were performed simultaneously in 5 high hip BMD (Bone Mineral Density) subjects and 5 low hip BMD subjects. SPIA (Signaling Pathway Impact Analysis) and PCST (Prize Collecting Steiner Tree) algorithm were used to perform pathway-enrichment analysis and construct the interaction networks. Through integrating the transcriptomic and epigenomic data, firstly we identified 3 genes (FAM50A, ZNF473 and TMEM55B) and one miRNA (hsa-mir-4291) which showed the consistent association evidence from both gene expression and methylation data; secondly in network analysis we identified an interaction network module with 12 genes and 11 miRNAs including AKT1, STAT3, STAT5A, FLT3, hsa-mir-141 and hsa-mir-34a which have been associated with BMD in previous studies. This module revealed the crosstalk among miRNAs, mRNAs and DNA methylation and showed four potential regulatory patterns of gene expression to influence the BMD status. In conclusion, the integration of multiple layers of omics can yield in-depth results than analysis of individual omics data respectively. Integrative analysis from transcriptomics and epigenomic data improves our ability to identify causal genetic factors, and more importantly uncover functional regulation pattern of multi-omics for osteoporosis etiology. </AbstractText>
26390436	230	242	Osteoporosis	Disease	MESH:D010024
26390436	454	466	osteoporosis	Disease	MESH:D010024
26390436	616	619	BMD	Disease	MESH:D010024
26390436	621	641	Bone Mineral Density	Disease	MESH:D010024
26390436	666	669	BMD	Disease	MESH:D010024
26390436	1304	1307	BMD	Disease	MESH:D010024
26390436	1486	1489	BMD	Disease	MESH:D010024
26390436	1834	1846	osteoporosis	Disease	MESH:D010024

26390437|t|-No title-
26390437|a|<AbstractText Label="null" NlmCategory="UNLABELLED">There is increased interest in using microRNAs (miRNAs) as biomarkers in different diseases. Present in body fluids, it is controversial whether or not they are mainly enclosed in exosomes, thus we studied if urinary miRNAs are concentrated inside exosomes and if the presence of systemic lupus erythematosus with or without lupus nephritis modifies their distribution pattern. We quantified specific miRNAs in urine of patients with systemic lupus erythematosus (n = 38) and healthy controls (n = 12) by quantitative reverse-transcription PCR in cell-free urine, exosome-depleted supernatant and exosome pellet obtained by ultracentrifugation. In control group, miR-335* and miR-302d were consistently higher in exosomes than in exosome-depleted supernatant, and miR-200c and miR-146a were higher in cell-free fraction. In lupus patients, all urinary miRNAs tested were mainly in exosomes with lower levels outside them (p<0.05 and p<0.01, respectively). This pattern is especially relevant in patients with active lupus nephritis compared to the control group or to the SLE patients in absence of lupus nephritis, with miR-146a being the most augmented (100-fold change, p<0.001). Among the exosomal miRNAs tested, only the miR-146a discriminates the presence of active lupus nephritis. In conclusion, urinary miRNAs are contained primarily in exosomes in systemic lupus erythematosus, and the main increment was found in the presence of active lupus nephritis. These findings underscore the attractiveness of exosomal miRNAs in urine, a non-invasive method, as potential renal disease markers. </AbstractText>
26390437	343	371	systemic lupus erythematosus	Disease	MESH:D008180
26390437	388	403	lupus nephritis	Disease	MESH:D008181
26390437	497	525	systemic lupus erythematosus	Disease	MESH:D008180
26390437	1072	1094	active lupus nephritis	Disease	MESH:D008181
26390437	1135	1138	SLE	Disease	MESH:D008180
26390437	1162	1177	lupus nephritis	Disease	MESH:D008181
26390437	1328	1350	active lupus nephritis	Disease	MESH:D008181
26390437	1421	1449	systemic lupus erythematosus	Disease	MESH:D008180
26390437	1503	1525	active lupus nephritis	Disease	MESH:D008181
26390437	1637	1650	renal disease	Disease	MESH:D052177

26390438|t|-No title-
26390438|a|<AbstractText Label="PURPOSE" NlmCategory="OBJECTIVE">To measure the distance between the optic disc center and the fovea (DFD) and to assess its associations. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">The population-based cross-sectional Beijing Eye Study 2011 included 3468 individuals aged 50+ years. The DFD was measured on fundus photographs. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">Readable fundus photographs were available for 2836 (81.8%) individuals. Mean DFD was 4.76 ± 0.34mm (median: 4.74 mm; range: 3.76-6.53mm). In multivariate analysis, longer DFD was associated with longer axial length (P<0.001; standardized correlation coefficient beta: 0.62), higher prevalence of axially high myopia (P<0.001; beta:0.06), shallower anterior chamber depth (P<0.001; beta:-0.18), thinner lens thickness (P = 0.004; beta: -0.06), smaller optic disc-fovea angle (P = 0.02; beta: -0.04), larger parapapillary alpha zone (P = 0.008; beta: 0.05), larger parapapillary beta/gamma zone (P<0.001; beta: 0.11), larger optic disc area (P<0.001; beta: 0.08), lower degree of cortical cataract (P = 0.002; beta: -0.08), and lower prevalence of age-related macular degeneration (P = 0.001; beta: -0.06). Bruch´s membrane opening-fovea distance (DFD minus disc radius minus parapapillary beta/gamma zone width) in non-glaucomatous eyes was not significantly (P = 0.60) related with axial length in emmetropic or axially myopic eyes (axial length ?23.5 mm), while it increased significantly (P<0.001; r: 0.32) with longer axial length in eyes with an axial length of <23.5mm. Ratio of mean DFD to disc diameter was 2.65 ± 0.30. If the ratio of disc-fovea distance to disc diameter was considered constant and if the individual disc diameter was calculated as the individual disc-fovea distance divided by the constant factor of 2.65, the resulting calculated disc diameter differed from the directly measured disc diameter by 0.16 ±0.13 mm (median: 0.13 mm, range: 0.00-0.89 mm) or 8.9 ± 7.3% (median: 7.4%; range: 0.00-70%) of the measured disc diameter. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">DFD (mean: 4.76mm) increases with longer axial length, larger parapapillary alpha zone and parapapillary beta/gamma zone, and larger disc area. The axial elongation associated increase in DFD was due to an enlargement of parapapillary beta/gamma zone while the Bruch's membrane opening-fovea distance did not enlarge with longer axial length. This finding may be of interest for the process of emmetropization and myopization. Due to its variability, the disc-fovea distance has only limited clinical value as a relative size unit for structures at the posterior pole. </AbstractText>
26390438	654	666	axial length	Disease	MESH:D007870
26390438	761	767	myopia	Disease	MESH:D009216
26390438	790	822	shallower anterior chamber depth	Disease	OMIM:602482
26390438	1015	1044	parapapillary beta/gamma zone	Disease	MESH:D020179
26390438	1130	1147	cortical cataract	Disease	OMIM:611391
26390438	1210	1230	macular degeneration	Disease	MESH:D008268
26390438	1326	1355	parapapillary beta/gamma zone	Disease	MESH:D020179
26390438	1366	1387	non-glaucomatous eyes	Disease	MESH:D005128
26390438	1434	1446	axial length	Disease	MESH:D007870
26390438	1450	1483	emmetropic or axially myopic eyes	Disease	MESH:C537792
26390438	1485	1497	axial length	Disease	MESH:D007870
26390438	1573	1585	axial length	Disease	MESH:D007870
26390438	1602	1614	axial length	Disease	MESH:D007870
26390438	2223	2235	axial length	Disease	MESH:D007870
26390438	2273	2302	parapapillary beta/gamma zone	Disease	MESH:D020179
26390438	2403	2432	parapapillary beta/gamma zone	Disease	MESH:D020179
26390438	2511	2523	axial length	Disease	MESH:D007870

26390439|t|-No title-
26390439|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Photoplethysmography (PPG) is a non-invasive optical technique for detecting microvascular blood volume changes in tissues. Its ease of use, low cost and convenience make it an attractive area of research in the biomedical and clinical communities. Nevertheless, its single spot monitoring and the need to apply a PPG sensor directly to the skin limit its practicality in situations such as perfusion mapping and healing assessments or when free movement is required. The introduction of fast digital cameras into clinical imaging monitoring and diagnosis systems, the desire to reduce the physical restrictions, and the possible new insights that might come from perfusion imaging and mapping inspired the evolution of conventional PPG technology to imaging PPG (IPPG). IPPG is a noncontact method that can detect heartgenerated pulse waves by means of peripheral blood perfusion measurements. Since its inception, IPPG has attracted significant public interest and provided opportunities to improve personal healthcare. This study presents an overview of the wide range of IPPG systems currently being introduced along with examples of their application in various physiological assessments. We believe that the widespread acceptance of IPPG is happening, and it will dramatically accelerate the promotion of this healthcare model in the near future. </AbstractText>

26390440|t|-No title-
26390440|a|<AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">This study aims to develop a new quantitative image feature analysis scheme and investigate its role along with 2 genomic biomarkers namely, protein expression of the excision repair cross-complementing 1 (ERCC1) genes and a regulatory subunit of ribonucleotide reductase (RRM1), in predicting cancer recurrence risk of Stage I non-small-cell lung cancer (NSCLC) patients after surgery. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">By using chest computed tomography images, we developed a computer-aided detection scheme to segment lung tumors and computed tumor-related image features. After feature selection, we trained a Naïve Bayesian network based classifier using 8 image features and a Multilayer Perceptron classifier using 2 genomic biomarkers to predict cancer recurrence risk, respectively. Two classifiers were trained and tested using a dataset with 79 Stage I NSCLC cases, a synthetic minority oversampling technique and a leave-one-case-out validation method. A fusion method was also applied to combine prediction scores of two classifiers. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">AUC (areas under ROC curves) values are 0.78±0.06 and 0.68±0.07 when using the image feature and genomic biomarker based classifiers, respectively. AUC value significantly increased to 0.84±0.05 (p<0.05) when fusion of two classifier-generated prediction scores using an equal weighting factor. </AbstractText><AbstractText Label="CONCLUSION" NlmCategory="CONCLUSIONS">A quantitative image feature based classifier yielded significantly higher discriminatory power than a genomic biomarker based classifier in predicting cancer recurrence risk. Fusion of prediction scores generated by the two classifiers further improved prediction performance. </AbstractText><AbstractText Label="SIGNIFICANCE" NlmCategory="CONCLUSIONS">We demonstrated a new approach that has potential to assist clinicians in more effectively managing Stage I NSCLC patients to reduce cancer recurrence risk. </AbstractText>
26390440	361	367	cancer	Disease	MESH:D009369
26390440	387	421	Stage I non-small-cell lung cancer	Disease	MESH:D002289
26390440	423	428	NSCLC	Disease	MESH:D002289
26390440	614	633	segment lung tumors	Disease	MESH:C537538
26390440	638	652	computed tumor	Disease	MESH:D009369
26390440	855	861	cancer	Disease	MESH:D009369
26390440	957	970	Stage I NSCLC	Disease	MESH:D002289
26390440	1736	1742	cancer	Disease	MESH:D009369
26390440	2038	2051	Stage I NSCLC	Disease	MESH:D002289
26390440	2071	2077	cancer	Disease	MESH:D009369

26390441|t|-No title-
26390441|a|<AbstractText Label="OBJECTIVE" NlmCategory="OBJECTIVE">The goal of this study is to develop an automated algorithm to quantify background EEG dynamics in term neonates with hypoxic ischemic encephalopathy (HIE). </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">The recorded EEG signal is adaptively segmented and the segments with low amplitudes are detected. Next, depending on the spatial distribution of the low amplitude segments, the first part of the algorithm detects (dynamic) interburst intervals (dIBIs) and performs well on the relatively artifact-free EEG periods and well defined burst-suppression EEG periods. However, on testing the algorithm on EEG recordings of more than 48h per neonate, a significant number of misclassified and dubious detections were encountered. Therefore, as the next step, we applied machine learning classifiers to differentiate between definite dIBI detections and misclassified ones. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">The developed algorithm achieved a true positive detection rate of 98%, 97%, 88% and 95% for four duration-related dIBI groups that we subsequently defined. </AbstractText><AbstractText Label="CONCLUSION" NlmCategory="CONCLUSIONS">We benchmarked our algorithm with an expert diagnostic interpretation of EEG periods (1h long) and demonstrated its effectiveness in clinical practice. We show that the detection algorithm effectively discriminates challenging cases encountered within mild and moderate background abnormalities. </AbstractText><AbstractText Label="SIGNIFICANCE" NlmCategory="CONCLUSIONS">dIBI detection algorithm improves identification of neonates with good clinical outcome as compared to the classification based on the classical burst-suppression interburst interval. </AbstractText>
26390441	185	216	hypoxic ischemic encephalopathy	Disease	MESH:D020925
26390441	218	221	HIE	Disease	MESH:D020925
26390441	1526	1550	background abnormalities	Disease	MESH:D002869

26390442|t|-No title-
26390442|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We fabricated a carbon nanotube (CNT)/adhesive polydimethylsiloxane (aPDMS) composite-based dry electroencephalograph (EEG) electrode for capacitive measuring of EEG signals. As research related to brain-computer interface applications has advanced, the presence of hairs on a patient's scalp has continued to present an obstacle to recorder EEG signals using dry electrodes. The CNT/aPDMS electrode developed here is elastic, highly conductive, self-adhesive, and capable of making conformal contact with and attaching to a hairy scalp. Onto the conductive disk, hundreds of conductive pillars coated with Parylene C insulation layer were fabricated. A CNT/aPDMS layer was attached on the disk to transmit biosignals to the pillar. The top of disk was designed to be solderable, which enables the electrode to be connected with a variety of commercial EEG acquisition systems. The mechanical and electrical characteristics of the electrode were tested, and the performances of the electrodes were evaluated by recording EEGs, including alpha rhythms, auditory-evoked potentials, and steady-state visually-evoked potentials. The results revealed that the electrode provided a high signal-to-noise ratio with good tolerance for motion. Almost no leakage current was observed. Although preamplifiers with ultra-high input impedance have been essential for previous capacitive electrodes, the EEGs were recorded here by directly connecting a commercially available EEG acquisition system to the electrode to yield high quality signals comparable to those obtained using conventional wet electrodes. </AbstractText>
26390442	715	732	A CNT/aPDMS layer	Disease	MESH:C536058

26390443|t|-No title-
26390443|a|<AbstractText Label="GOAL" NlmCategory="OBJECTIVE">The detection of brain responses corresponding to the presentation of a particular class of images is a challenge in Brain-Machine Interface (BMI). Current systems based on the detection of brain responses during rapid serial visual presentation (RSVP) tasks possess advantages for both healthy and disabled people, as they are gaze-independent and can offer a high throughput. </AbstractText><AbstractText Label="METHODS" NlmCategory="METHODS">We propose a novel paradigm based on a dual RSVP task that assumes a low target probability. Two streams of images are presented simultaneously on the screen, the second stream is identical to the first one, but delayed in time. Participants were asked to detect images containing a person. They follow the first stream until they see a target image, then change their attention to the second stream until the target image reappears, finally they change their attention back to the first stream. </AbstractText><AbstractText Label="RESULTS" NlmCategory="RESULTS">The performance of single-trial detection was evaluated on both streams and their combination of the decisions with signal recorded with magnetoencephalography (MEG) during the dual RSVP task. We compare classification performance across different sets of channels (magnetometers, gradiometers) with a BLDA classifier with inputs obtained after spatial filtering. </AbstractText><AbstractText Label="CONCLUSION" NlmCategory="CONCLUSIONS">The results suggest that single-trial detection can be obtained with an area under the ROC curve superior to 0.95, and that an almost perfect accuracy can be obtained with some subjects thanks to the combination of the decisions from two trials, without doubling the duration of the experiment. </AbstractText><AbstractText Label="SIGNIFICANCE" NlmCategory="CONCLUSIONS">The present results show that a reliable accuracy can be obtained with MEG for target detection during a dual RSVP task. </AbstractText>

26390444|t|-No title-
26390444|a|-No abstract-

26390445|t|-No title-
26390445|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This paper addresses detection and localization of human activities in videos. We focus on activities that may have variable spatiotemporal arrangements of parts, and numbers of actors. Such activities are represented by a Sum-Product Network (SPN). A product node in SPN represents a particular arrangement of parts, and a sum node represents alternative arrangements. The sums and products are hierarchically organized, and grounded onto space-time windows covering the video. The windows provide evidence about the activity classes based on the Counting Grid (CG) model of visual words. This evidence is propagated bottom-up and topdown to parse the SPN graph for the explanation of the video. The node connectivity and model parameters of SPN and CG are jointly learned under two settings, weakly supervised, and supervised. For evaluation, we use our new Volleyball dataset, along with the benchmark datasets VIRAT, UT- Interactions, KTH, and TRECVID MED 2011. Our video classification and activity localization are superior to those of the state of the art on these datasets. </AbstractText>
26390445	611	624	Counting Grid	Disease	MESH:D009845
26390445	626	628	CG	Disease	MESH:D009845
26390445	814	816	CG	Disease	MESH:D009845

26390446|t|-No title-
26390446|a|<AbstractText Label="null" NlmCategory="UNLABELLED">In this paper, we propose a visual tracker based on a metric-weighted linear representation of appearance. In order to capture the interdependence of different feature dimensions, we develop two online distance metric learning methods using proximity comparison information and structured output learning. The learned metric is then incorporated into a linear representation of appearance. We show that online distance metric learning significantly improves the robustness of the tracker, especially on those sequences exhibiting drastic appearance changes. In order to bound growth in the number of training samples, we design a time-weighted reservoir sampling method. Moreover, we enable our tracker to automatically perform object identification during the process of object tracking, by introducing a collection of static template samples belonging to several object classes of interest. Object identification results for an entire video sequence are achieved by systematically combining the tracking information and visual recognition at each frame. Experimental results on challenging video sequences demonstrate the effectiveness of the method for both inter-frame tracking and object identification. </AbstractText>

26390447|t|-No title-
26390447|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Standard edge detection operators such as the Laplacian of Gaussian and the gradient of Gaussian can be used to track contours in image sequences. When using edge operators, a contour, which is determined on a frame of the sequence, is simply used as a starting contour to locate the nearest contour on the subsequent frame. However, the strategy used to look for the nearest edge points may not work when tracking contours of non isolated gray level discontinuities. In these cases, strategies derived from the optical flow equation, which look for similar gray level distributions, appear to be more appropriate since these can work with a lower frame rate than that needed for strategies based on pure edge detection operators. However, an optical flow strategy tends to propagate the localization errors through the sequence and an additional edge detection procedure is essential to compensate for such a drawback. In this paper a spatio-temporal intensity moment is proposed which integrates the two basic functions of edge detection and tracking. </AbstractText>

26390448|t|-No title-
26390448|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Typical feature selection methods choose an optimal global feature subset that is applied over all regions of the sample space. In contrast, in this paper we propose a novel localized feature selection (LFS) approach whereby each region of the sample space is associated with its own distinct optimized feature set, which may vary both in membership and size across the sample space. This allows the feature set to optimally adapt to local variations in the sample space. An associated method for measuring the similarities of a query datum to each of the respective classes is also proposed. The proposed method makes no assumptions about the underlying structure of the samples; hence the method is insensitive to the distribution of the data over the sample space. The method is efficiently formulated as a linear programming optimization problem. Furthermore, we demonstrate the method is robust against the over-fitting problem. Experimental results on eleven synthetic and real-world data sets demonstrate the viability of the formulation and the effectiveness of the proposed algorithm. In addition we show several examples where localized feature selection produces better results than a global feature selection method. </AbstractText>

26390449|t|-No title-
26390449|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Ultrasound-modulated optical tomography is an emerging biomedical imaging modality which uses the spatially localised acoustically-driven modulation of coherent light as a probe of the structure and optical properties of biological tissues. In this work we begin by providing an overview of forward modelling methods, before deriving a linearised diffusion-style model which calculates the first-harmonic modulated flux measured on the boundary of a given domain. We derive and examine the correlation measurement density functions of the model which describe the sensitivity of the modality to perturbations in the optical parameters of interest. Finally, we employ said functions in the development of an adjoint-assisted gradient based image reconstruction method, which ameliorates the computational burden and memory requirements of a traditional Newton-based optimisation approach. We validate our work by performing reconstructions of optical absorption and scattering in twoand three-dimensions using simulated measurements with 1% proportional Gaussian noise, and demonstrate the successful recovery of the parameters to within 5% of their true values when the resolution of the ultrasound raster probing the domain is sufficient to delineate perturbing inclusions. </AbstractText>

26390450|t|-No title-
26390450|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We propose a new method for the joint design of k-space trajectory and RF pulse in 3D small-tip tailored excitation. Designing time-varying RF and gradient waveforms for a desired 3D target excitation pattern in MRI poses a non-linear, non-convex, constrained optimization problem with relatively large problem size that is difficult to solve directly. Existing joint pulse design approaches are therefore typically restricted to predefined trajectory types such as EPI or stack-of-spirals that intrinsically satisfy the gradient maximum and slew rate constraints and reduce the problem size (dimensionality) dramatically, but lead to suboptimal excitation accuracy for a given pulse duration. Here we use a 2nd-order B-spline basis that can be fitted to an arbitrary k-space trajectory, and allows the gradient constraints to be implemented efficiently. We show that this allows the joint optimization problem to be solved with quite general k-space trajectories. Starting from an arbitrary initial trajectory, we first approximate the trajectory using B-spline basis, and then optimize the corresponding coefficients. We evaluate our method in simulation using four different k-space initializations: stack-of-spirals, SPINS, KTpoints, and a new method based on KT-points. In all cases, our approach leads to substantial improvement in excitation accuracy for a given pulse duration. We also validated our method for inner-volume excitation using phantom experiments. The computation is fast enough for online applications. </AbstractText>

26390451|t|-No title-
26390451|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This paper proposes a new method to correct beam hardening artifacts caused by the presence of metal in polychromatic X-ray computed tomography (CT) without degrading the intact anatomical images. Metal artifacts due to beam-hardening, which are a consequence of X-ray beam polychromaticity, are becoming an increasingly important issue affecting CT scanning as medical implants become more common in a generally aging population. The associated higher-order beam-hardening factors can be corrected via analysis of the mismatch between measured sinogram data and the ideal forward projectors in CT reconstruction by considering the known geometry of highattenuation objects. Without prior knowledge of the spectrum parameters or energy-dependent attenuation coefficients, the proposed correction allows the background CT image (i.e., the image before its corruption by metal artifacts) to be extracted from the uncorrected CT image. Computer simulations and phantom experiments demonstrate the effectiveness of the proposed method to alleviate beam hardening artifacts. </AbstractText>
26390451	167	206	polychromatic X-ray computed tomography	Disease	MESH:D004370

26390452|t|-No title-
26390452|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We propose new quasi-interpolators for the continuous reconstruction of sampled images, combining a narrowlysupported piecewise-polynomial kernel and an efficient digital filter. In other words, our quasi-interpolators fit within the generalized sampling framework and are straightforward to use. We go against standard practice and optimize for approximation quality over the entire Nyquist range, rather than focusing exclusively on the asymptotic behavior as the sample spacing goes to zero. In contrast to previous work, we jointly optimize with respect to all degrees of freedom available in both the kernel and the digital filter.We consider linear, quadratic, and cubic schemes, offering different trade-offs between quality and computational cost. Experiments with compounded rotations and translations over a range of input images confirm that, due to the additional degrees of freedom and the more realistic objective function, our new quasi-interpolators perform better than the state-of-the-art, at a similar computational cost. </AbstractText>

26390453|t|-No title-
26390453|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Palmprint recognition (PR) is an effective technology for personal recognition. A main problem which deteriorates the performance of PR is the deformations of palmprint images. This problem becomes more severe on contactless occasions, in which images are acquired without any guiding mechanisms, and hence critically limits the applications of PR. To solve the deformation problems, in this work, a model for non-linearly deformed palmprint matching is derived by approximating non-linear deformed palmprint images with piecewise-linear deformed stable regions. Based on this model, a novel approach for deformed palmprint matching, named as key point based block growing (KPBG), is proposed. In KPBG, an iterative MSAC algorithm based on SIFT features is devised to compute piecewise-linear transformations to approximate the non-linear deformations of palmprints, and then the stable regions complying with the linear transformations are decided using a block growing algorithm. Palmprint feature extraction and matching are performed over these stable regions to compute matching scores for decision. Experiments on several public palmprint databases show that the proposed models and the KPBG approach can effectively solve the deformation problem in palmprint verification and outperform the state-of-the-art methods. </AbstractText>

26390454|t|-No title-
26390454|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We propose a novel error tolerant optimization approach to generate a high-quality photometric compensated projection. The application of a non-linear color mapping function does not require radiometric pre-calibration of cameras or projectors. This characteristic improves the compensation quality compared to related linear methods if this approach is used with devices that apply complex color processing, such as single-chip DLP projectors. Our approach consists of a sparse sampling of the projector's color gamut and non-linear scattered data interpolation to generate the per-pixel mapping from the projector to camera colors in real-time. To avoid out-of-gamut artifacts, the input image's luminance is automatically adjusted locally in an optional off-line optimization step that maximizes the achievable contrast while preserving smooth input gradients without significant clipping errors. To minimize the appearance of color artifacts at high-frequency reflectance changes of the surface due to usually unavoidable slight projector vibrations and movement (drift), we show that a drift measurement and analysis step, when combined with per-pixel compensation image optimization, significantly decreases the visibility of such artifacts. </AbstractText>

26390455|t|-No title-
26390455|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Nonnegative Tucker decomposition (NTD) is a powerful tool for the extraction of nonnegative parts-based and physically meaningful latent components from high-dimensional tensor data while preserving the natural multilinear structure of data. However, as the data tensor often has multiple modes and is large-scale, existing NTD algorithms suffer from a very high computational complexity in terms of both storage and computation time, which has been one major obstacle for practical applications of NTD. To overcome these disadvantages, we show how low (multilinear) rank approximation (LRA) of tensors is able to significantly simplify the computation of the gradients of the cost function, upon which a family of efficient first-order NTD algorithms are developed. Besides dramatically reducing the storage complexity and running time, the new algorithms are quite flexible and robust to noise because any well-established LRA approaches can be applied. We also show how nonnegativity incorporating sparsity substantially improves the uniqueness property and partially alleviates the curse of dimensionality of the Tucker decompositions. Simulation results on synthetic and real-world data justify the validity and high efficiency of the proposed NTD algorithms. </AbstractText>
26390455	38	95	NlmCategory="UNLABELLED">Nonnegative Tucker decomposition	Disease	MESH:C536923
26390455	97	100	NTD	Disease	MESH:C536923
26390455	387	390	NTD	Disease	MESH:C536923
26390455	562	565	NTD	Disease	MESH:C536923
26390455	800	803	NTD	Disease	MESH:C536923
26390455	1312	1315	NTD	Disease	MESH:C536923

26390456|t|-No title-
26390456|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This paper presents a novel visual tracking method based on linear representation. First, we present a novel probability continuous outlier model (PCOM) to depict the continuous outliers within the linear representation model. In the proposed model, the element of the noisy observation sample can be either represented by a PCA subspace with small Guassian noise or treated as an arbitrary value with a uniform prior, in which a simple Markov random field model is adopted to exploit the spatial consistency information among outliers (or inliners). Then, we derive the objective function of the PCOM method from the perspective of probability theory. The objective function can be solved iteratively by using the outlier-free least squares and standard max-flow/min-cut steps. Finally, for visual tracking, we develop an effective observation likelihood function based on the proposed PCOM method and background information, and design a simple update scheme. Both qualitative and quantitative evaluations demonstrate that our tracker achieves considerable performance in terms of both accuracy and speed. </AbstractText>

26390457|t|-No title-
26390457|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We propose a novel formulation for relaxed analysisbased sparsity in multiple dictionaries as a general type of prior for images, and apply it for Bayesian estimation in image restoration problems. Our formulation of a `2-relaxed `0 pseudonorm prior allows for an especially simple MAP estimation iterative marginal optimization algorithm, whose convergence we prove. We achieve a significant speed-up over the direct (static) solution by using dynamically evolving parameters through the estimation loop. As an added heuristic twist, we fix in advance the number of iterations, and then empirically optimize the involved parameters according to two performance benchmarks. The resulting constrained dynamic method is not just fast and effective, it is also highly robust and flexible. First, it is able to provide an outstanding trade-off between computational load and performance, in visual and objective -MSE, SSIM- terms, for a large variety of degradation tests, using the same set of parameter values for all tests. Second, the performance benchmark can be easily adapted to specific types of degradation, image classes, and even performance criteria. Third, it allows for using simultaneously several dictionaries with complementary features. This unique combination makes ours a highly practical deconvolution method. </AbstractText>
26390457	345	348	MAP	Disease	MESH:C535477

26390458|t|-No title-
26390458|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Blind image deconvolution involves two key objectives, latent image and blur estimation. For latent image estimation, we propose a fast deconvolution algorithm, which uses an image prior of nondimensional Gaussianity measure to enforce sparsity and an undetermined boundary condition methodology to reduce boundary artifacts. For blur estimation, a linear inverse problem with normalization and nonnegative constraints must be solved. However, the normalization constraint is ignored in many blind image deblurring methods, mainly because it makes the problem less tractable. In this paper, we show that the normalization constraint can be very naturally incorporated into the estimation process by using a Dirichlet distribution to approximate the posterior distribution of the blur. Making use of variational Dirichlet approximation, we provide a blur posterior approximation that takes into account the uncertainty of the estimate and removes noise in the estimated kernel. Experiments with synthetic and real data demonstrate that the proposed method is very competitive to state-of-the-art blind image restoration methods. </AbstractText>

26390459|t|-No title-
26390459|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Horror content sharing on the Web is a growing phenomenon that can interfere with our daily life and affect the mental health of those involved. As an important form of expression, horror images have their own characteristics that can evoke extreme emotions. In this paper, we present a novel context-aware multi-instance learning (CMIL) algorithm for horror image recognition. The CMIL identifies horror images and picks out the regions that cause the sensation of horror in these horror images. It obtains contextual cues among adjacent regions in an image using a random walk on a contextual graph. Borrowing the strength of the Fuzzy Support Vector Machine (FSVM), we define a heuristic optimization procedure based on the FSVM to search for the optimal classifier for the CMIL. To improve the initialization of the CMIL, we propose a novel visual saliency model based on tensor analysis. The average saliency value of each segmented region is set as its initial fuzzy membership in the CMIL. The advantage of the tensor-based visual saliency model is that it not only adaptively selects features, but also dynamically determines fusion weights for saliency value combination from different feature subspaces. The effectiveness of the proposed CMIL model is demonstrated by its use in horror image recognition on two large scale image sets collected from the Internet. </AbstractText>

26390460|t|-No title-
26390460|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This study presents a new visual tracking framework based on an adaptive color attention tuned local sparse model. The histograms of sparse coefficients of all patches in an object are pooled together according to their spatial distribution. A particle filter methodology is used as the location model to predict candidates for object verification during tracking. Since color is an important visual clue to distinguish objects from background, we calculate the color similarity between objects in previous frames and the candidates in current frame, which is adopted as color attention to tune the local sparse representation based appearance similarity measurement between the object template and candidates. The color similarity can be calculated efficiently with hash coded color names, which helps the tracker find more reliable objects during tracking. We use a flexible local sparse coding of the object to evaluate the degeneration degree of the appearance model, based on which we build a model updating mechanism to alleviate drifting caused by temporal varying multi-factors. Experiments on 76 challenging benchmark color sequences and the evaluation under the object tracking benchmark protocol demonstrate the superiority of the proposed tracker over state-of-the-art methods in accuracy. </AbstractText>

26390461|t|-No title-
26390461|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present a dictionary learning approach to compensate for the transformation of faces due to changes in view point, illumination, resolution, etc. The key idea of our approach is to force domain-invariant sparse coding, i.e., design a consistent sparse representation of the same face in different domains. In this way, classifiers trained on the sparse codes in the source domain consisting of frontal faces can be applied to the target domain (consisting of faces in different poses, illumination conditions, etc) without much loss in recognition accuracy. The approach is to first learn a domain base dictionary, and then describe each domain shift (identity, pose, illumination) using a sparse representation over the base dictionary. The dictionary adapted to each domain is expressed as sparse linear combinations of the base dictionary. In the context of face recognition, with the proposed compositional dictionary approach, a face image can be decomposed into sparse representations for a given subject, pose and illumination respectively. This approach has three advantages: first, the extracted sparse representation for a subject is consistent across domains and enables pose and illumination insensitive face recognition. Second, sparse representations for pose and illumination can subsequently be used to estimate the pose and illumination condition of a face image. Finally, by composing sparse representations for subject and the different domains, we can also perform pose alignment and illumination normalization. Extensive experiments using two public face datasets are presented to demonstrate the effectiveness of the proposed approach for face recognition. </AbstractText>

26390462|t|-No title-
26390462|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Context information is widely used in computer vision for tracking arbitrary objects. Most existing works focus on how to distinguish the object of interest from background or how to use keypoint-based supporters as their auxiliary information to assist them in tracking. However, in most cases, how to discover and represent both the intrinsic property inside the object and the surrounding context is still an open problem. In this paper, we propose a unified context learning framework that can effectively capture spatio-temporal relations, prior knowledge and motion consistency to enhance the tracker's performance. The proposed Weighted Part Context Tracker (WPCT) consists of an appearance model, an internal relation model and a context relation model. The appearance model represents the appearances of the object and parts. The internal relation model utilizes the parts inside the object to describe the spatio-temporal structure property directly, while the context relation model takes advantage of the latent intersection between the object and background regions. Then the three models are embedded in a max-margin structured learning framework. Furthermore, prior label distribution is added, which can effectively exploit the spatial prior knowledge for learning the classifier and inferring the object state in the tracking process. Meanwhile, we define online update functions to decide when to update WPCT as well as how to reweight the parts. Extensive experiments and comparisons with the state-of-the-arts demonstrate the effectiveness of the proposed method. </AbstractText>

26390463|t|-No title-
26390463|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Similarity measure is an important block in image registration. Most traditional intensity-based similarity measures (e.g., SSD, CC, and MI) assume a stationary image and pixel-by-pixel independence. These similarity measures ignore the correlation between pixel intensities; hence, perfect image registration can not be achieved, especially in the presence of spatially varying intensity distortions. Here, we assume that spatially varying intensity distortion (such as bias field) is a low-rank matrix. Based on this assumption, we formulate the image registration problem as a nonlinear and low-rank matrix decomposition (NLLRMD). So, image registration and correction of spatially varying intensity distortion are simultaneously achieved. We illustrate the uniqueness of NLLRMD, and therefore we propose the rank of difference image as a robust similarity in the presence of spatially varying intensity distortion. Finally, by incorporating the Gaussian noise, we introduce rank-induced similarity measure (RISM) based on the singular values of the difference image. This measure produces clinically acceptable registration results on both simulated and real-world problems examined in this study, and outperforms other state-of-the-art measures such as the residual complexity approach. </AbstractText>
26390463	187	190	SSD	Disease	OMIM:608445
26390463	643	686	nonlinear and low-rank matrix decomposition	Disease	MESH:D009800
26390463	688	694	NLLRMD	Disease	MESH:D009800
26390463	838	844	NLLRMD	Disease	MESH:D009800

26390464|t|-No title-
26390464|a|<AbstractText Label="null" NlmCategory="UNLABELLED">System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology. </AbstractText>

26390465|t|-No title-
26390465|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Datasets commonly include multi-value (set-typed) attributes that describe set memberships over elements, such as genres per movie or courses taken per student. Set-typed attributes describe rich relations across elements, sets, and the set intersections. Increasing the number of sets results in a combinatorial growth of relations and creates scalability challenges. Exploratory tasks (e.g. selection, comparison) have commonly been designed in separation for set-typed attributes, which reduces interface consistency. To improve on scalability and to support rich, contextual exploration of set-typed data, we present AggreSet. AggreSet creates aggregations for each data dimension: sets, set-degrees, set-pair intersections, and other attributes. It visualizes the element count per aggregate using a matrix plot for set-pair intersections, and histograms for set lists, set-degrees and other attributes. Its non-overlapping visual design is scalable to numerous and large sets. AggreSet supports selection, filtering, and comparison as core exploratory tasks. It allows analysis of set relations inluding subsets, disjoint sets and set intersection strength, and also features perceptual set ordering for detecting patterns in set matrices. Its interaction is designed for rich and rapid data exploration. We demonstrate results on a wide range of datasets from different domains with varying characteristics, and report on expert reviews and a case study using student enrollment and degree data with assistant deans at a major public university. </AbstractText>

26390466|t|-No title-
26390466|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system. </AbstractText>

26390467|t|-No title-
26390467|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Visualization of the trajectories of moving objects leads to dense and cluttered images, which hinders exploration and understanding. It also hinders adding additional visual information, such as direction, and makes it difficult to interactively extract traffic flows, i.e., subsets of trajectories. In this paper we present our approach to visualize traffic flows and provide interaction tools to support their exploration. We show an overview of the traffic using a density map. The directions of traffic flows are visualized using a particle system on top of the density map. The user can extract traffic flows using a novel selection widget that allows for the intuitive selection of an area, and filtering on a range of directions and any additional attributes. Using simple, visual set expressions, the user can construct more complicated selections. The dynamic behaviors of selected flows may then be shown in annotation windows in which they can be interactively explored and compared. We validate our approach through use cases where we explore and analyze the temporal behavior of aircraft and vessel trajectories, e.g., landing and takeoff sequences, or the evolution of flight route density. The aircraft use cases have been developed and validated in collaboration with domain experts. </AbstractText>

26390468|t|-No title-
26390468|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Finding good projections of n-dimensional datasets into a 2D visualization domain is one of the most important problems in Information Visualization. Users are interested in getting maximal insight into the data by exploring a minimal number of projections. However, if the number is too small or improper projections are used, then important data patterns might be overlooked. We propose a data-driven approach to find minimal sets of projections that uniquely show certain data patterns. For this we introduce a dissimilarity measure of data projections that discards affine transformations of projections and prevents repetitions of the same data patterns. Based on this, we provide complete data tours of at most n=2 projections. Furthermore, we propose optimal paths of projection matrices for an interactive data exploration. We illustrate our technique with a set of state-of-the-art real high-dimensional benchmark datasets. </AbstractText>

26390469|t|-No title-
26390469|a|<AbstractText Label="null" NlmCategory="UNLABELLED">General visualization tools typically require manual specification of views: analysts must select data variables and then choose which transformations and visual encodings to apply. These decisions often involve both domain and visualization design expertise, and may impose a tedious specification process that impedes exploration. In this paper, we seek to complement manual chart construction with interactive navigation of a gallery of automatically-generated visualizations. We contribute Voyager, a mixed-initiative system that supports faceted browsing of recommended charts chosen according to statistical and perceptual measures. We describe Voyager's architecture, motivating design principles, and methods for generating and interacting with visualization recommendations. In a study comparing Voyager to a manual visualization specification tool, we find that Voyager facilitates exploration of previously unseen data and leads to increased data variable coverage. We then distill design implications for visualization tools, in particular the need to balance rapid exploration and targeted question-answering. </AbstractText>

26390470|t|-No title-
26390470|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality. </AbstractText>

26390471|t|-No title-
26390471|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Comparing multiple variables to select those that effectively characterize complex entities is important in a wide variety of domains - geodemographics for example. Identifying variables that correlate is a common practice to remove redundancy, but correlation varies across space, with scale and over time, and the frequently used global statistics hide potentially important differentiating local variation. For more comprehensive and robust insights into multivariate relations, these local correlations need to be assessed through various means of defining locality. We explore the geography of this issue, and use novel interactive visualization to identify interdependencies in multivariate data sets to support geographically informed multivariate analysis. We offer terminology for considering scale and locality, visual techniques for establishing the effects of scale on correlation and a theoretical framework through which variation in geographic correlation with scale and locality are addressed explicitly. Prototype software demonstrates how these contributions act together. These techniques enable multiple variables and their geographic characteristics to be considered concurrently as we extend visual parameter space analysis (vPSA) to the spatial domain. We find variable correlations to be sensitive to scale and geography to varying degrees in the context of energy-based geodemographics. This sensitivity depends upon the calculation of locality as well as the geographical and statistical structure of the variable. </AbstractText>

26390472|t|-No title-
26390472|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts. </AbstractText>

26390473|t|-No title-
26390473|a|<AbstractText Label="null" NlmCategory="UNLABELLED">In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward. </AbstractText>

26390474|t|-No title-
26390474|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency. </AbstractText>

26390475|t|-No title-
26390475|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices. </AbstractText>
26390475	38	90	NlmCategory="UNLABELLED">Computational fluid dynamic	Disease	MESH:C537947
26390475	92	95	CFD	Disease	MESH:C537947
26390475	198	216	cerebral aneurysms	Disease	MESH:D002532
26390475	439	455	aneurysm rupture	Disease	MESH:D017542
26390475	693	733	simulated cerebral aneurysm hemodynamics	Disease	MESH:D002532
26390475	1170	1173	CFD	Disease	MESH:C537947

26390476|t|-No title-
26390476|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots. </AbstractText>

26390477|t|-No title-
26390477|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Prior research into network layout has focused on fast heuristic techniques for layout of large networks, or complex multi-stage pipelines for higher quality layout of small graphs. Improvements to these pipeline techniques, especially for orthogonal-style layout, are difficult and practical results have been slight in recent years. Yet, as discussed in this paper, there remain significant issues in the quality of the layouts produced by these techniques, even for quite small networks. This is especially true when layout with additional grouping constraints is required. The first contribution of this paper is to investigate an ultra-compact, grid-like network layout aesthetic that is motivated by the grid arrangements that are used almost universally by designers in typographical layout. Since the time when these heuristic and pipeline-based graph-layout methods were conceived, generic technologies (MIP, CP and SAT) for solving combinatorial and mixed-integer optimization problems have improved massively. The second contribution of this paper is to reassess whether these techniques can be used for high-quality layout of small graphs. While they are fast enough for graphs of up to 50 nodes we found these methods do not scale up. Our third contribution is a large-neighborhood search meta-heuristic approach that is scalable to larger networks. </AbstractText>
26390477	976	979	MIP	Disease	MESH:C535689
26390477	981	983	CP	Disease	MESH:D002547

26390478|t|-No title-
26390478|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Sketching designs has been shown to be a useful way of planning and considering alternative solutions. The use of lofidelity prototyping, especially paper-based sketching, can save time, money and converge to better solutions more quickly. However, this design process is often viewed to be too informal. Consequently users do not know how to manage their thoughts and ideas (to first think divergently, to then finally converge on a suitable solution). We present the Five Design Sheet (FdS) methodology. The methodology enables users to create information visualization interfaces through lo-fidelity methods. Users sketch and plan their ideas, helping them express different possibilities, think through these ideas to consider their potential effectiveness as solutions to the task (sheet 1); they create three principle designs (sheets 2,3 and 4); before converging on a final realization design that can then be implemented (sheet 5). In this article, we present (i) a review of the use of sketching as a planning method for visualization and the benefits of sketching, (ii) a detailed description of the Five Design Sheet (FdS) methodology, and (iii) an evaluation of the FdS using the System Usability Scale, along with a case-study of its use in industry and experience of its use in teaching. </AbstractText>

26390479|t|-No title-
26390479|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts. </AbstractText>

26390480|t|-No title-
26390480|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations. </AbstractText>

26390481|t|-No title-
26390481|a|<AbstractText Label="null" NlmCategory="UNLABELLED">In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach. </AbstractText>

26390482|t|-No title-
26390482|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present TimeSpan, an exploratory visualization tool designed to gain a better understanding of the temporal aspects of the stroke treatment process. Working with stroke experts, we seek to provide a tool to help improve outcomes for stroke victims. Time is of critical importance in the treatment of acute ischemic stroke patients. Every minute that the artery stays blocked, an estimated 1.9 million neurons and 12 km of myelinated axons are destroyed. Consequently, there is a critical need for efficiency of stroke treatment processes. Optimizing time to treatment requires a deep understanding of interval times. Stroke health care professionals must analyze the impact of procedures, events, and patient attributes on time-ultimately, to save lives and improve quality of life after stroke. First, we interviewed eight domain experts, and closely collaborated with two of them to inform the design of TimeSpan. We classify the analytical tasks which a visualization tool should support and extract design goals from the interviews and field observations. Based on these tasks and the understanding gained from the collaboration, we designed TimeSpan, a web-based tool for exploring multi-dimensional and temporal stroke data. We describe how TimeSpan incorporates factors from stacked bar graphs, line charts, histograms, and a matrix visualization to create an interactive hybrid view of temporal data. From feedback collected from domain experts in a focus group session, we reflect on the lessons we learned from abstracting the tasks and iteratively designing TimeSpan. </AbstractText>
26390482	372	387	ischemic stroke	Disease	MESH:D002544

26390483|t|-No title-
26390483|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new "human-centred" methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand. </AbstractText>

26390484|t|-No title-
26390484|a|<AbstractText Label="null" NlmCategory="UNLABELLED">When data categories have strong color associations, it is useful to use these semantically meaningful concept-color associations in data visualizations. In this paper, we explore how linguistic information about the terms defining the data can be used to generate semantically meaningful colors. To do this effectively, we need first to establish that a term has a strong semantic color association, then discover which color or colors express it. Using co-occurrence measures of color name frequencies from Google n-grams, we define a measure for colorability that describes how strongly associated a given term is to any of a set of basic color terms. We then show how this colorability score can be used with additional semantic analysis to rank and retrieve a representative color from Google Images. Alternatively, we use symbolic relationships defined by WordNet to select identity colors for categories such as countries or brands. To create visually distinct color palettes, we use k-means clustering to create visually distinct sets, iteratively reassigning terms with multiple basic color associations as needed. This can be additionally constrained to use colors only in a predefined palette. </AbstractText>

26390485|t|-No title-
26390485|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Models of human perception - including perceptual "laws" - can be valuable tools for deriving visualization design recommendations. However, it is important to assess the explanatory power of such models when using them to inform design. We present a secondary analysis of data previously used to rank the effectiveness of bivariate visualizations for assessing correlation (measured with Pearson's r) according to the well-known Weber-Fechner Law. Beginning with the model of Harrison et al. [1], we present a sequence of refinements including incorporation of individual differences, log transformation, censored regression, and adoption of Bayesian statistics. Our model incorporates all observations dropped from the original analysis, including data near ceilings caused by the data collection process and entire visualizations dropped due to large numbers of observations worse than chance. This model deviates from Weber's Law, but provides improved predictive accuracy and generalization. Using Bayesian credibility intervals, we derive a partial ranking that groups visualizations with similar performance, and we give precise estimates of the difference in performance between these groups. We find that compared to other visualizations, scatterplots are unique in combining low variance between individuals and high precision on both positively- and negatively- correlated data. We conclude with a discussion of the value of data sharing and replication, and share implications for modeling similar experimental data. </AbstractText>

26390486|t|-No title-
26390486|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Node-link diagrams provide an intuitive way to explore networks and have inspired a large number of automated graph layout strategies that optimize aesthetic criteria. However, any particular drawing approach cannot fully satisfy all these criteria simultaneously, producing drawings with visual ambiguities that can impede the understanding of network structure. To bring attention to these potentially problematic areas present in the drawing, this paper presents a technique that highlights common types of visual ambiguities: ambiguous spatial relationships between nodes and edges, visual overlap between community structures, and ambiguity in edge bundling and metanodes. Metrics, including newly proposed metrics for abnormal edge lengths, visual overlap in community structures and node/edge aggregation, are proposed to quantify areas of ambiguity in the drawing. These metrics and others are then displayed using a heatmap-based visualization that provides visual feedback to developers of graph drawing and visualization approaches, allowing them to quickly identify misleading areas. The novel metrics and the heatmap-based visualization allow a user to explore ambiguities in graph layouts from multiple perspectives in order to make reasonable graph layout choices. The effectiveness of the technique is demonstrated through case studies and expert reviews. </AbstractText>

26390487|t|-No title-
26390487|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We introduce a set of integrated interaction techniques to interpret and interrogate dimensionality-reduced data. Projection techniques generally aim to make a high-dimensional information space visible in form of a planar layout. However, the meaning of the resulting data projections can be hard to grasp. It is seldom clear why elements are placed far apart or close together and the inevitable approximation errors of any projection technique are not exposed to the viewer. Previous research on dimensionality reduction focuses on the efficient generation of data projections, interactive customisation of the model, and comparison of different projection techniques. There has been only little research on how the visualization resulting from data projection is interacted with. We contribute the concept of probing as an integrated approach to interpreting the meaning and quality of visualizations and propose a set of interactive methods to examine dimensionality-reduced data as well as the projection itself. The methods let viewers see approximation errors, question the positioning of elements, compare them to each other, and visualize the influence of data dimensions on the projection space. We created a web-based system implementing these methods, and report on findings from an evaluation with data analysts using the prototype to examine multidimensional datasets. </AbstractText>
26390487	942	967	quality of visualizations	Disease	MESH:D012640

26390488|t|-No title-
26390488|a|<AbstractText Label="null" NlmCategory="UNLABELLED">In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participantgenerated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable "at-a-glance" are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one. </AbstractText>

26390489|t|-No title-
26390489|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. Onedimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques. </AbstractText>

26390490|t|-No title-
26390490|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Meteorologists process and analyze weather forecasts using visualization in order to examine the behaviors of and relationships among weather features. In this design study conducted with meteorologists in decision support roles, we identified and attempted to address two significant common challenges in weather visualization: the employment of inconsistent and often ineffective visual encoding practices across a wide range of visualizations, and a lack of support for directly visualizing how different weather features relate across an ensemble of possible forecast outcomes. In this work, we present a characterization of the problems and data associated with meteorological forecasting, we propose a set of informed default encoding choices that integrate existing meteorological conventions with effective visualization practice, and we extend a set of techniques as an initial step toward directly visualizing the interactions of multiple features over an ensemble forecast. We discuss the integration of these contributions into a functional prototype tool, and also reflect on the many practical challenges that arise when working with weather data. </AbstractText>

26390491|t|-No title-
26390491|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Decades of research have repeatedly shown that people perform poorly at estimating and understanding conditional probabilities that are inherent in Bayesian reasoning problems. Yet in the medical domain, both physicians and patients make daily, life-critical judgments based on conditional probability. Although there have been a number of attempts to develop more effective ways to facilitate Bayesian reasoning, reports of these findings tend to be inconsistent and sometimes even contradictory. For instance, the reported accuracies for individuals being able to correctly estimate conditional probability range from 6% to 62%. In this work, we show that problem representation can significantly affect accuracies. By controlling the amount of information presented to the user, we demonstrate how text and visualization designs can increase overall accuracies to as high as 77%. Additionally, we found that for users with high spatial ability, our designs can further improve their accuracies to as high as 100%. By and large, our findings provide explanations for the inconsistent reports on accuracy in Bayesian reasoning tasks and show a significant improvement over existing methods. We believe that these findings can have immediate impact on risk communication in health-related fields. </AbstractText>

26390492|t|-No title-
26390492|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Graphics convey numerical information very efficiently, but rely on a different set of mental processes than tabular displays. Here, we present a study relating demographic characteristics and visual skills to perception of graphical lineups. We conclude that lineups are essentially a classification test in a visual domain, and that performance on the lineup protocol is associated with general aptitude, rather than specific tasks such as card rotation and spatial manipulation. We also examine the possibility that specific graphical tasks may be associated with certain visual skills and conclude that more research is necessary to understand which visual skills are required in order to understand certain plot types. </AbstractText>
26390492	150	188	mental processes than tabular displays	Disease	MESH:D010335

26390493|t|-No title-
26390493|a|<AbstractText Label="null" NlmCategory="UNLABELLED">We present a method for realtime reconstruction of an animating human body, which produces a sequence of deforming meshes representing a given performance captured by a single commodity depth camera. We achieve realtime single-view mesh completion by enhancing the parameterized SCAPE model. Our method, which we call Realtime SCAPE, performs full-body reconstruction without the use of markers. In Realtime SCAPE, estimations of body shape parameters and pose parameters, needed for reconstruction, are decoupled. Intrinsic body shape is first precomputed for a given subject, by determining shape parameters with the aid of a body shape database. Subsequently, per-frame pose parameter estimation is performed by means of linear blending skinning (LBS); the problem is decomposed into separately finding skinning weights and transformations. The skinning weights are also determined offline from the body shape database, reducing online reconstruction to simply finding the transformations in LBS. Doing so is formulated as a linear variational problem; carefully designed constraints are used to impose temporal coherence and alleviate artifacts. Experiments demonstrate that our method can produce full-body mesh sequences with high fidelity. </AbstractText>

26390494|t|-No title-
26390494|a|<AbstractText Label="null" NlmCategory="UNLABELLED">The characterization of peripheral nerve fiber distributions, in terms of diameter or velocity, is of clinical significance because information associated with these distributions can be utilized in the differential diagnosis of peripheral neuropathies. Electro-diagnostic techniques can be applied to the investigation of peripheral neuropathies and can yield valuable diagnostic information while being minimally invasive. Nerve conduction velocity studies are single parameter tests that yield no detailed information regarding the characteristics of the population of nerve fibers that contribute to the compound evoked potential. Decomposition of the compound evoked potential, such that the velocity or diameter distribution of the contributing nerve fibers may be determined, is necessary if information regarding the population of contributing nerve fibers is to be ascertained from the electro-diagnostic study. In this work, a perturbation based decomposition of compound evoked potentials is proposed that facilitates determination of the fiber diameter distribution associated with the compound evoked potential. The decomposition is based on representing the single fiber evoked potential, associated with each diameter class, as being perturbed by contributions, of varying degree, from all the other diameter class single fiber evoked potentials. The resultant estimator of the contributing nerve fiber diameter distribution is valid for relatively large separations in diameter classes. It is also useful in situations where the separation between diameter classes is small and the concomitant single fiber evoked potentials are not orthogonal. </AbstractText>
26390494	292	315	peripheral neuropathies	Disease	MESH:D010523
26390494	386	409	peripheral neuropathies	Disease	MESH:D010523

26390495|t|-No title-
26390495|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Recently, feature selection and dimensionality reduction have become fundamental tools for many data mining tasks, especially for processing high-dimensional data such as gene expression microarray data. Gene expression microarray data comprises up to hundreds of thousands of features with relatively small sample size. Because learning algorithms usually do not work well with this kind of data, a challenge to reduce the data dimensionality arises. A huge number of gene selection techniques are applied to select a subset of relevant features for model construction and to seek for better cancer classification performance. This paper presents the basic taxonomy of feature selection and also reviews the state-of-the-art gene selection methods by grouping the literatures into three categories: supervised, unsupervised and semi-supervised. The comparison of experimental results on top 5 representative gene expression datasets indicates that the classification accuracy of unsupervised and semi-supervised feature selection is competitive with supervised feature selection. </AbstractText>
26390495	656	662	cancer	Disease	MESH:D009369

26390496|t|-No title-
26390496|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Graph edit distance is one of the most flexible and general graph matching models available. The major drawback of graph edit distance, however, is its computational complexity that restricts its applicability to graphs of rather small size. Recently the authors of the present paper introduced a general approximation framework for the graph edit distance problem. The basic idea of this specific algorithm is to first compute an optimal assignment of independent local graph structures (including substitutions, deletions, and insertions of nodes and edges). This optimal assignment is complete and consistent with respect to the involved nodes of both graphs and can thus be used to instantly derive an admissible (yet suboptimal) solution for the original graph edit distance problem in O(n3) time. For large scale graphs or graph sets, however, the cubic time complexity may still be too high. Therefore, we propose to use suboptimal algorithms with quadratic rather than cubic time for solving the basic assignment problem. In particular, the present paper introduces five different greedy assignment algorithms in the context of graph edit distance approximation. In an experimental evaluation we show that these methods have great potential for further speeding up the computation of graph edit distance while the approximated distances remain sufficiently accurate for graph based pattern classification. </AbstractText>

26390497|t|-No title-
26390497|a|<AbstractText Label="null" NlmCategory="UNLABELLED">In biomedical text mining tasks, distributed word representation has succeeded in capturing semantic regularities, but most of them are shallow-window based models, which are not sufficient for expressing the meaning of words. To represent words using deeper information, we make explicit the semantic regularity to emerge in word relations, including dependency relations and context relations, and propose a novel architecture for computing continuous vector representation by leveraging those relations.The performance of our model is measured on word analogy task and Protein-Protein Interaction Extraction (PPIE) task. Experimental results show that our method performs overall better than other word representation models on word analogy task and have many advantages on biomedical text mining. </AbstractText>

26390498|t|-No title-
26390498|a|<AbstractText Label="null" NlmCategory="UNLABELLED">mRNA translation is a complex process involving the progression of ribosomes on the mRNA, resulting in the synthesis of proteins, and is subject to multiple layers of regulation. This process has been modelled using different formalisms, both stochastic and deterministic. Recently, we introduced a Probabilistic Boolean modelling framework for mRNA translation, which possesses the advantage of tools for numerically exact computation of steady state probability distribution, without requiring simulation. Here we extend this model to incorporate both random sequential and parallel update rules, and demonstrate its effectiveness in various settings, including its flexibility in accommodating additional static and dynamic biological complexities and its role in parameter sensitivity analysis. In these applications, the results from the model analysis match those of TASEP model simulations. Importantly the proposed modelling framework maintains the stochastic aspects of mRNA translation and provides a way to exactly calculate probability distributions, providing additional tools of analysis in this context. Finally the proposed modelling methodology provides an alternative approach to the understanding of the mRNA translation process, by bridging the gap between existing approaches, providing new analysis tools and contributing to a more robust platform for modelling and understanding translation. </AbstractText>

26390499|t|-No title-
26390499|a|<AbstractText Label="null" NlmCategory="UNLABELLED">The implementation of biological neural networks is a key objective of the neuromorphic research field. Astrocytes are the largest cell population in the brain. With the discovery of calcium wave propagation through astrocyte networks, now it is more evident that neuronal networks alone may not explain functionality of the strongest natural computer, the brain. Models of cortical function must now account for astrocyte activities as well as their relationships with neurons in encoding and manipulation of sensory information. From an engineering viewpoint, astrocytes provide feedback to both presynaptic and postsynaptic neurons to regulate their signaling behaviors. This paper presents a modified neural glial interaction model that allows a convenient digital implementation. This model can reproduce relevant biological astrocyte behaviors, which provide appropriate feedback control in regulating neuronal activities in the central nervous system (CNS). Accordingly, we investigate the feasibility of a digital implementation for a single astrocyte constructed by connecting a two coupled FitzHugh Nagumo (FHN) neuron model to an implementation of the proposed astrocyte model using neuron-astrocyte interactions. Hardware synthesis, physical implementation on FPGA, and theoretical analysis confirm that the proposed neuron astrocyte model, with significantly low hardware cost, can mimic biological behavior such as the regulation of postsynaptic neuron activity and the synaptic transmission mechanisms. </AbstractText>

26390500|t|-No title-
26390500|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This paper describes an electrocardiograph (ECG) monitoring SoC using a non-volatile MCU (NVMCU) and a noise-tolerant instantaneous heartbeat detector. The novelty of this work is the combination of the non-volatile MCU for normally off computing and a noise-tolerant-QRS (heartbeat) detector to achieve both low-power and noise tolerance. To minimize the stand-by current of MCU, a non-volatile flip-flop and a 6T-4C NVRAM are used. Proposed plate-line charge-share and bit-line non-precharge techniques also contribute to mitigate the active power overhead of 6T-4C NVRAM. The proposed accurate heartbeat detector uses coarse-fine autocorrelation and a template matching technique. Accurate heartbeat detection also contributes system-level power reduction because the active ratio of ADC and digital block can be reduced using heartbeat prediction. Measurement results show that the fully integrated ECG-SoC consumes 6.14 ? A including 1.28- ?A non-volatile MCU and 0.7- ?A heartbeat detector. </AbstractText>
26390500	747	775	Accurate heartbeat detection	Disease	MESH:D005117
26390500	850	871	ADC and digital block	Disease	MESH:D006327

26390501|t|-No title-
26390501|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This paper presents a 3.3×3.2 mm(2) system-on-chip (SoC) fabricated in AMS 0.35 ?m 2P/4M CMOS for closed-loop regulation of brain dopamine. The SoC uniquely integrates neurochemical sensing, on-the-fly chemometrics, and feedback-controlled electrical stimulation to realize a "neurochemostat" by maintaining brain levels of electrically evoked dopamine between two user-set thresholds. The SoC incorporates a 90 ?W, custom-designed, digital signal processing (DSP) unit for real-time processing of neurochemical data obtained by 400 V/s fast-scan cyclic voltammetry (FSCV) with a carbon-fiber microelectrode (CFM). Specifically, the DSP unit executes a chemometrics algorithm based upon principal component regression (PCR) to resolve in real time electrically evoked brain dopamine levels from pH change and CFM background-current drift, two common interferents encountered using FSCV with a CFM in vivo. Further, the DSP unit directly links the chemically resolved dopamine levels to the activation of the electrical microstimulator in on-off-keying (OOK) fashion. Measured results from benchtop testing, flow injection analysis (FIA), and biological experiments with an anesthetized rat are presented. </AbstractText>

26390502|t|-No title-
26390502|a|<AbstractText Label="null" NlmCategory="UNLABELLED">By incorporating feedback around systems we wish to manipulate, it is possible to improve their performance and robustness properties to meet pre-specified design objectives. For decades control engineers have been successfully implementing feedback controllers for complex mechanical and electrical systems such as aircraft and sports cars. Natural biological systems use feedback extensively for regulation and adaptation but apart from the most basic designs, there is no systematic framework for designing feedback controllers in Synthetic Biology. In this paper we describe how classical approaches from linear control theory can be used to close the loop. This includes the design of genetic circuits using feedback control and the presentation of a biological phase lag controller. </AbstractText>

26390503|t|-No title-
26390503|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Recent advances in synthetic biology call for robust, flexible and efficient in silico optimization methodologies. We present a Pareto design approach for the bi-level optimization problem associated to the overproduction of specific metabolites in Escherichia coli. Our method efficiently explores the high dimensional genetic manipulation space, finding a number of trade-offs between synthetic and biological objectives, hence furnishing a deeper biological insight to the addressed problem and important results for industrial purposes. We demonstrate the computational capabilities of our Pareto-oriented approach comparing it with state-of-the-art heuristics in the overproduction problems of i) 1,4-butanediol, ii) myristoyl-CoA, i ii) malonyl-CoA , iv) acetate and v) succinate. We show that our algorithms are able to gracefully adapt and scale to more complex models and more biologically-relevant simulations of the genetic manipulations allowed. The Results obtained for 1,4-butanediol overproduction significantly outperform results previously obtained, in terms of 1,4-butanediol to biomass formation ratio and knock-out costs. In particular overproduction percentage is of +662.7%, from 1.425 mmolh(-1)gDW(-1) (wild type) to 10.869 mmolh(-1)gDW(-1), with a knockout cost of 6. Whereas, Pareto-optimal designs we have found in fatty acid optimizations strictly dominate the ones obtained by the other methodologies, e.g., biomass and myristoyl-CoA exportation improvement of +21.43% (0.17 h(-1)) and +5.19% (1.62 mmolh(-1)gDW(-1)), respectively. Furthermore CPU time required by our heuristic approach is more than halved. Finally we implement pathway oriented sensitivity analysis, epsilon-dominance analysis and robustness analysis to enhance our biological understanding of the problem and to improve the optimization algorithm capabilities. </AbstractText>

26390504|t|-No title-
26390504|a|<AbstractText Label="null" NlmCategory="UNLABELLED">In this study, we presented an efficient and unobtrusive tactile feedback system, which is used to train dental technicians in carving tasks using a wax stick and knife. First, we developed a method for generating performance metrics using a model-based estimation of clearance angles between an object's surface and the carving blade. The calculated clearance angles are compared with desired angles obtained from expert operators. Then, angular errors are presented as tactile cues to the user's finger pads through electrical stimuli at the middle phalanx of the index finger and the thumb. Subsequently, we conducted a feasibility test with novice dental technicians, who showed improvement in initial clearance angles of carving strokes. Moreover, the results showed significant reduction in the occurrence rate of poor-carving when using the proposed system. From these results, we concluded that electrotactile augmentation can provide effective guidance for carving tasks. </AbstractText>
26390504	502	516	angular errors	Disease	MESH:D012030

26390505|t|-No title-
26390505|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Recent technological trends in mobile/wearable devices and sensors have been enabling an increasing number of people to collect and store their "lifelog" easily in their daily lives. Beyond exercise behavior change of individual users, our research focus is on the behavior change of teams, based on life-logging technologies and lifelog sharing. In this paper, we propose and evaluate six different types of lifelog sharing models among team members for their exercise promotion, leveraging the concepts of "competition" and "collaboration." According to our experimental mobile web application for exercise promotion and an extensive user study conducted with a total of 64 participants over a period of three weeks, the model with "competition" technique resulted in the most effective performance for competitive teams, such as sports teams. </AbstractText>

26390506|t|-No title-
26390506|a|<AbstractText Label="null" NlmCategory="UNLABELLED">Since it first appeared, differential evolution (DE), one of the most successful evolutionary algorithms, has been studied by many researchers. Theoretical and empirical studies of the parameters and strategies have been conducted, and numerous variants have been proposed. Opposition-based DE (ODE), one of such variants, combines DE with opposition-based learning (OBL) to obtain a high-quality solution with low-computational effort. In this paper, we propose a novel OBL using a beta distribution with partial dimensional change and selection switching and combine it with DE to enhance the convergence speed and searchability. Our proposed algorithm is tested on various test functions and compared with standard DE and other ODE variants. The results indicate that the proposed algorithm outperforms the comparison group, especially in terms of solution accuracy. </AbstractText>

26390507|t|-No title-
26390507|a|<AbstractText Label="null" NlmCategory="UNLABELLED">This paper is concerned with the synchronization problem for a class of switched neural networks (SNNs) with time-varying delays. First, a new crucial lemma which includes and extends the classical exponential stability theorem is constructed. Then by using the lemma, new algebraic criteria of ?-type synchronization (synchronization with general decay rate) for SNNs are established via the designed nonlinear feedback control. The ?-type synchronization which is in a general framework is obtained by introducing a ?-type function. It contains exponential synchronization, polynomial synchronization, and other synchronization as its special cases. The results of this paper are general, and they also complement and extend some previous results. Finally, numerical simulations are carried out to demonstrate the effectiveness of the obtained results. </AbstractText>

26390508|t|-No title-
26390508|a|-No abstract-

26390509|t|-No title-
26390509|a|-No abstract-

26390510|t|-No title-
26390510|a|-No abstract-

26390511|t|-No title-
26390511|a|-No abstract-

26390512|t|-No title-
26390512|a|-No abstract-

26390513|t|-No title-
26390513|a|-No abstract-

26390514|t|-No title-
26390514|a|-No abstract-

26390515|t|-No title-
26390515|a|-No abstract-

26390516|t|-No title-
26390516|a|<AbstractText Label="AIMS" NlmCategory="OBJECTIVE">Percutaneous revascularisation triage has not been evaluated in randomised controlled trials of patients with non-ST-segment elevation acute coronary syndromes (NSTE-ACS) and multivessel disease. As a result, current guidelines are not available. The objective of our meta-analysis was to investigate the use of percutaneous coronary intervention (PCI) in culprit and non-culprit vessels. </AbstractText><AbstractText Label="METHODS AND RESULTS" NlmCategory="RESULTS">We undertook a meta-analysis of controlled studies where patients were assigned to multivessel PCI or culprit vessel PCI. Summary odds ratios (OR) for all-cause mortality, myocardial infarction, unplanned revascularisation and major adverse cardiac events (MACE) were calculated using random- or fixed-effect models. Six registry studies (n=5,414) were included in this meta-analysis. There was no difference in the rate of mortality (OR, 0.85; 95% CI: 0.70 to 1.04; p=0.114) or myocardial infarction (OR, 0.75; 95% CI: 0.43 to 1.32; p=0.319) between the two treatment groups. Multivessel PCI may decrease long-term MACE (OR, 0.69; 95% CI: 0.51 to 0.93; p=0.015) and unplanned revascularisation (OR, 0.64; 95% CI: 0.45 to 93; p=0.018) compared with culprit vessel PCI. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">No significant difference was demonstrated in the long-term risk of myocardial infarction and mortality between multivessel PCI and culprit vessel PCI. Therefore, multivessel PCI may be a safe and reasonable option for NSTE-ACS patients with multivessel disease. </AbstractText>
26390516	702	723	myocardial infarction	Disease	MESH:D009203
26390516	771	785	cardiac events	Disease	MESH:D004362
26390516	1009	1030	myocardial infarction	Disease	MESH:D009203
26390516	1442	1463	myocardial infarction	Disease	MESH:D009203

26390517|t|-No title-
26390517|a|<AbstractText Label="AIMS" NlmCategory="OBJECTIVE">The aim of the present study was to compare vascular healing response between the first-generation sirolimus-eluting stent (SES) and the second-generation everolimus-eluting stent (EES) by using optical coherence tomography (OCT). </AbstractText><AbstractText Label="METHODS AND RESULTS" NlmCategory="RESULTS">The RESET was a prospective, multicentre, randomised, open-label trial comparing EES and SES. Of the 3,197 patients enrolled in the RESET, nine-month follow-up OCT after stent implantation was performed in 100 patients (48 EES-treated lesions in 44 patients and 62 SES-treated lesions in 56 patients), thus constituting the OCT substudy population. The percentage of uncovered struts per lesion (8±15% vs. 14±19%, p=0.031) and cross-sections with >30% uncovered struts per lesion (6±14% vs. 18±29%, p=0.009) was significantly lower in EES compared with SES. The frequency of DES-treated lesions with incomplete stent apposition (8 [17%] vs. 29 [47%], p<0.001) was significantly lower in EES compared with SES. Intra-stent thrombus was comparably observed between EES and SES (1 [2%] vs. 5 [8%], p=0.229). </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">Compared with SES, EES was associated with a favourable vascular response at nine months after stent implantation. </AbstractText>

26390518|t|-No title-
26390518|a|<AbstractText Label="AIMS" NlmCategory="OBJECTIVE">Coronary protection with guidewires and an undeployed coronary balloon or stent positioned in the coronary artery is a pre-emptive technique to manage coronary obstruction during transcatheter aortic valve implantation (TAVI). We investigated the feasibility and safety of left main (LM) protection during TAVI. </AbstractText><AbstractText Label="METHODS AND RESULTS" NlmCategory="RESULTS">Twenty-five out of 623 patients who underwent TAVI at our institute were deemed to be at increased risk of LM compromise mainly due to a low LM ostium height, significant LM disease or a previous bioprosthetic valve. A pre-emptive LM protection technique was therefore used in these cases. Five patients (20%) had pre-TAVI significant non-revascularised LM stenosis, and four patients (16%) had a prior LM ostial stent without pre-TAVI in-stent restenosis. Twelve patients had extremely low LM height (mean height 6.7±2.4 mm; range 1.1-8.9 mm). Seven patients (25%) had valve-in-valve (VIV) procedures. LM compromise occurred in five out of 25 cases; all were treated successfully with emergency LM stenting. Nine patients underwent successful planned LM procedures following TAVI. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">The LM protection technique should be considered in patients deemed to be at increased risk of LM compromise. This was found to be helpful in the prompt diagnosis and treatment of LM compromise following TAVI. </AbstractText>
26390518	624	634	LM disease	Disease	MESH:C537693

26390519|t|-No title-
26390519|a|-No abstract-

26390520|t|-No title-
26390520|a|<AbstractText Label="AIMS" NlmCategory="OBJECTIVE">We aimed to investigate whether sympathetic denervation of the heart and kidney had similar effects on ventricular effective refractory period (ERP) and action potential duration (APD) restitution properties in a canine model. </AbstractText><AbstractText Label="METHODS AND RESULTS" NlmCategory="RESULTS">Twenty-four anaesthetised open-chest dogs (17-20 kg) were assigned to a sham operation group (n=8), a cardiac sympathetic denervation group (CSD, n=8) or a renal sympathetic denervation group (RSD, n=8). CSD was performed by ablating the caudal half of the LSG and T2-T4 thoracic sympathetic ganglia, while RSD was performed by ablating four sites on the adventitial surface of each renal artery. The ventricular electrophysiological properties were determined at four time points: baseline, 0 min, 30 min, and 60 min after interventions. The results showed that, when compared to the control group at the time point of 60 min after interventions, both CSD and RSD significantly reduced heart rate, prolonged the QT interval and ventricular ERP and APD, decreased the ERP dispersion and the slopes of APD restitution curves, and suppressed the APD alternans without affecting blood pressure and corrected QT interval. However, there were no significant differences in these parameters between CSD and RSD groups at the same time point. </AbstractText><AbstractText Label="CONCLUSIONS" NlmCategory="CONCLUSIONS">This study showed that sympathetic denervation of the heart and kidney induced similar electrophysiological effects in ventricles. </AbstractText>
26390520	106	141	denervation of the heart and kidney	Disease	MESH:D007674
26390520	470	507	cardiac sympathetic denervation group	Disease	MESH:D006732
26390520	509	512	CSD	Disease	MESH:D006732
26390520	524	559	renal sympathetic denervation group	Disease	MESH:D006732
26390520	561	564	RSD	Disease	MESH:D006732
26390520	572	575	CSD	Disease	MESH:D006732
26390520	675	678	RSD	Disease	MESH:D006732
26390520	1021	1024	CSD	Disease	MESH:D006732
26390520	1029	1032	RSD	Disease	MESH:D006732
26390520	1361	1364	CSD	Disease	MESH:D006732
26390520	1369	1372	RSD	Disease	MESH:D006732
26390520	1514	1549	denervation of the heart and kidney	Disease	MESH:D007674

26390521|t|-No title-
26390521|a|-No abstract-

